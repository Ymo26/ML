import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ------------------------------------------------
# 1. Load the Data
# ------------------------------------------------
df = pd.read_csv('hotel_booking.csv')

# Fill missing values
df['children'].fillna(0, inplace=True)
df['country'].fillna('Unknown', inplace=True)
df['agent'].fillna(0, inplace=True)
df['company'].fillna(0, inplace=True)

# Define features and target
features = [
    'lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights',
    'adults', 'children', 'babies', 'previous_cancellations',
    'previous_bookings_not_canceled', 'booking_changes',
    'days_in_waiting_list', 'adr', 'required_car_parking_spaces',
    'total_of_special_requests'
]
target = 'is_canceled'

# Remove rows with missing values in features + target
df_clean = df.dropna(subset=features + [target])

# ------------------------------------------------
# 2. Prepare Features (X) and Target (y)
# ------------------------------------------------
X = df_clean[features].values
y = df_clean[target].values

# ------------------------------------------------
# 3. Split the Data
# ------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

# ------------------------------------------------
# 4. Standardize Features
# ------------------------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ------------------------------------------------
# 5. Convert to XGBoost DMatrix
# ------------------------------------------------
dtrain = xgb.DMatrix(X_train_scaled, label=y_train)
dtest = xgb.DMatrix(X_test_scaled, label=y_test)

# ------------------------------------------------
# 6. Set XGBoost Parameters and Train
# ------------------------------------------------
params = {
    'objective': 'binary:logistic',  # Binary classification
    'max_depth': 6,
    'eta': 0.1,
    'eval_metric': 'logloss',
    'verbosity': 0  # Increase for more logging if desired
}

print("Training XGBoost model...")
bst = xgb.train(
    params,
    dtrain,
    num_boost_round=100,
    evals=[(dtest, 'eval')],
    early_stopping_rounds=10
)

# ------------------------------------------------
# 7. Make Predictions and Evaluate
# ------------------------------------------------
y_pred_prob = bst.predict(dtest)
y_pred = (y_pred_prob > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print(f"\nTest Accuracy: {accuracy:.4f}")
print(f"Test MSE: {mse:.4f}")

# ------------------------------------------------
# 8. Plot Confusion Matrix
# ------------------------------------------------
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
disp.plot(cmap=plt.cm.Blues)
plt.title("XGBoost Confusion Matrix")
plt.show()

# ------------------------------------------------
# 9. Plot Feature Importance
# ------------------------------------------------
xgb.plot_importance(bst)
plt.title("XGBoost Feature Importance")
plt.show()
